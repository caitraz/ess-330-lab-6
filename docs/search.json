[
  {
    "objectID": "lab6.html",
    "href": "lab6.html",
    "title": "Lab 6",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.7     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.0     ✔ yardstick    1.3.2\n✔ recipes      1.1.1     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nlibrary(powerjoin)\nlibrary(glue)\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\n\n\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              'data/camels_attributes_v2.0.pdf')\n\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\n\nlocal_files   &lt;- glue('data/camels_{types}.txt')\n\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \n\ncamels &lt;- power_full_join(camels ,by = 'gauge_id')\n\n\nQuestion 1\nThe zero_q_freq variable is the frequency of days where Q = 0 mm/day as a percentage, with Q being discharge, a measure of the volume of water flowing past a point on a stream.\n\n\nExploratory Data Analysis\n\nggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = q_mean)) +\n  scale_color_gradient(low = \"pink\", high = \"dodgerblue\") +\n  ggthemes::theme_map()\n\n\n\n\n\n\n\n\n\n\nQuestion 2\n\ncamels_long &lt;- camels %&gt;%\n  pivot_longer(cols = c(aridity, p_mean), \n               names_to = \"variable\", \n               values_to = \"value\")\n\nggplot(data = camels_long, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = value)) +  \n  scale_color_gradient(low = \"pink\", high = \"dodgerblue\") +\n  ggthemes::theme_map() +\n  facet_wrap(~ variable, scales = \"free\") + \n  scale_color_gradient(low = \"pink\", high = \"dodgerblue\") +\n  labs(\n    title = \"Maps of Aridity and P-Mean\",  \n    x = \"Longitude\", \n    y = \"Latitude\",  \n    color = \"Measurement Value\"  \n  )\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n\n\n\n\n\n\n\n\n\n\nModel Preparation & Building\n\ncamels |&gt; \n  select(aridity, p_mean, q_mean) |&gt; \n  drop_na() |&gt; \n  cor()\n\n           aridity     p_mean     q_mean\naridity  1.0000000 -0.7550090 -0.5817771\np_mean  -0.7550090  1.0000000  0.8865757\nq_mean  -0.5817771  0.8865757  1.0000000\n\n\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\", color = \"red\", linetype = 2) +\n  scale_color_viridis_c() +\n  theme_linedraw() + \n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  scale_color_viridis_c() +\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  scale_color_viridis_c(trans = \"log\") +\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\",\n        legend.key.width = unit(2.5, \"cm\"),\n        legend.key.height = unit(.5, \"cm\")) + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\") \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\n\ncamels &lt;- camels |&gt; \n  mutate(logQmean = log(q_mean))\n\ncamels_split &lt;- initial_split(camels, prop = 0.8)\ncamels_train &lt;- training(camels_split)\ncamels_test  &lt;- testing(camels_split)\n\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n\nrec &lt;-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %&gt;%\n  step_log(all_predictors()) %&gt;%\n  step_interact(terms = ~ aridity:p_mean) %&gt;%\n  step_naomit(all_predictors(), all_outcomes())\n\n\nbaked_data &lt;- prep(rec, camels_train) |&gt; \n  bake(new_data = NULL)\n\nlm_base &lt;- lm(logQmean ~ aridity * p_mean, data = baked_data)\nsummary(lm_base)\n\n\nCall:\nlm(formula = logQmean ~ aridity * p_mean, data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity        -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean          1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity:p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\nsummary(lm(logQmean ~ aridity + p_mean + aridity_x_p_mean, data = baked_data))\n\n\nCall:\nlm(formula = logQmean ~ aridity + p_mean + aridity_x_p_mean, \n    data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity          -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean            1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity_x_p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\n\n\ntest_data &lt;-  bake(prep(rec), new_data = camels_test)\ntest_data$lm_pred &lt;- predict(lm_base, newdata = test_data)\n\nmetrics(test_data, truth = logQmean, estimate = lm_pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\nggplot(test_data, aes(x = logQmean, y = lm_pred, colour = aridity)) +\n  scale_color_gradient2(low = \"brown\", mid = \"orange\", high = \"darkgreen\") +\n  geom_point() +\n  geom_abline(linetype = 2) +\n  theme_linedraw() + \n  labs(title = \"Linear Model: Observed vs Predicted\",\n       x = \"Observed Log Mean Flow\",\n       y = \"Predicted Log Mean Flow\",\n       color = \"Aridity\")\n\n\n\n\n\n\n\n\n\nlm_model &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\nlm_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(lm_model) %&gt;%\n  fit(data = camels_train) \n\n\nsummary(extract_fit_engine(lm_wf))$coefficients\n\n                   Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)      -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity          -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean            1.4843771 0.15511117   9.569762 4.022500e-20\naridity_x_p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\nsummary(lm_base)$coefficients\n\n                 Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)    -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity        -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean          1.4843771 0.15511117   9.569762 4.022500e-20\naridity:p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\n\n\nlm_data &lt;- augment(lm_wf, new_data = camels_test)\ndim(lm_data)\n\n[1] 135  61\n\n\n\nmetrics(lm_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\nggplot(lm_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nlibrary(baguette)\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\nrf_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(rf_model) %&gt;%\n  fit(data = camels_train) \n\nrf_data &lt;- augment(rf_wf, new_data = camels_test)\ndim(rf_data)\n\n[1] 135  60\n\nmetrics(rf_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.587\n2 rsq     standard       0.741\n3 mae     standard       0.363\n\nggplot(rf_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv) \n\nautoplot(wf)\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 4 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_rand_fore… Prepro… rmse    0.563  0.0247    10 recipe       rand…     1\n2 recipe_rand_fore… Prepro… rsq     0.771  0.0259    10 recipe       rand…     1\n3 recipe_linear_reg Prepro… rmse    0.569  0.0260    10 recipe       line…     2\n4 recipe_linear_reg Prepro… rsq     0.770  0.0223    10 recipe       line…     2\n\n\n\n\nQuestion 3\n\n# Boost Tree \nbt_model &lt;- boost_tree() %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n\nbt_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(bt_model) %&gt;%\n  fit(data = camels_train) \n\nbt_data &lt;- augment(bt_wf, new_data = camels_test)\ndim(bt_data)\n\n[1] 135  60\n\nmetrics(bt_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.631\n2 rsq     standard       0.702\n3 mae     standard       0.397\n\nggplot(bt_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n# Neural Network\nnnet_model &lt;- bag_mlp() %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\")\n\nnnet_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(nnet_model) %&gt;%\n  fit(data = camels_train) \n\nnnet_data &lt;- augment(nnet_wf, new_data = camels_test)\ndim(nnet_data)\n\n[1] 135  61\n\nmetrics(nnet_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.545\n2 rsq     standard       0.772\n3 mae     standard       0.337\n\nggplot(nnet_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n# Add to existing workflow\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model, nnet_model, bt_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv) \n\nautoplot(wf)\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 8 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_bag_mlp    Prepro… rmse    0.547  0.0282    10 recipe       bag_…     1\n2 recipe_bag_mlp    Prepro… rsq     0.786  0.0234    10 recipe       bag_…     1\n3 recipe_rand_fore… Prepro… rmse    0.564  0.0260    10 recipe       rand…     2\n4 recipe_rand_fore… Prepro… rsq     0.770  0.0266    10 recipe       rand…     2\n5 recipe_linear_reg Prepro… rmse    0.569  0.0260    10 recipe       line…     3\n6 recipe_linear_reg Prepro… rsq     0.770  0.0223    10 recipe       line…     3\n7 recipe_boost_tree Prepro… rmse    0.600  0.0289    10 recipe       boos…     4\n8 recipe_boost_tree Prepro… rsq     0.745  0.0268    10 recipe       boos…     4\n\n\nCompared to the other two models, the Neural Network model outperforms the other models and the Xgboost Regression model underperforms the other models. The linear model is still ranked above the Xgboost model and this could be because the tree-based method of the Xgboost model was not able to capture complexities in the relatively small dataset. However, the linear model was outperformed by the random forest model and neural network, suggesting a simple linear relationship is not sufficient to explain the interactions between terms. The flexible nature of the Neural Network model and its ability to capture complexities of the dataset and learn from complex interactions makes it the best model, as demonstrated in the above table and graph. For these reasons I would continue with the Neural Network model.\n\n\nBuild Your Own\n\n#Data Splitting\nset.seed(124)\n\ncamels &lt;- camels %&gt;%\n  mutate(logQmean = log(q_mean)) %&gt;%\n  select(logQmean, p_mean, aridity, soil_depth_pelletier, max_water_content, organic_frac, frac_snow, pet_mean, soil_depth_statsgo, elev_mean) %&gt;%\n  drop_na()\n\nc_split &lt;- initial_split(camels, prop = 0.8)\nc_train &lt;- training(c_split)\nc_test  &lt;- testing(c_split)\n\nc_cv &lt;- vfold_cv(c_train, v = 10)\n\n\n# Recipe\nrec2 &lt;-  recipe(logQmean ~ . , data = c_train) %&gt;%\n  step_scale(all_predictors()) %&gt;%\n  step_center(all_predictors()) \n\nI chose to use the above formula because it compares the predictors to the log transformed Q mean. Doing a log transformation on the Q mean proved to establish a more predictable relationship between the predictors p_mean and aridity, so I maintained this log transformation. Since there are many predictors, I chose to use step_scale and step_center to normalize the data on a universal scale and allow for more accurate model creation.\n\nc_baked &lt;- prep(rec2, c_train) |&gt; \n  bake(new_data = NULL)\n\nlm_base2 &lt;- lm(logQmean ~ . , data = c_baked)\nsummary(lm_base2)\n\n\nCall:\nlm(formula = logQmean ~ ., data = c_baked)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.7726 -0.1543  0.0502  0.2400  3.9490 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          -0.081749   0.022536  -3.627 0.000314 ***\np_mean                0.532187   0.039029  13.636  &lt; 2e-16 ***\naridity              -0.643846   0.049819 -12.924  &lt; 2e-16 ***\nsoil_depth_pelletier -0.077194   0.029114  -2.651 0.008256 ** \nmax_water_content     0.058350   0.043250   1.349 0.177877    \norganic_frac          0.005265   0.025468   0.207 0.836304    \nfrac_snow             0.287464   0.051639   5.567 4.14e-08 ***\npet_mean              0.137612   0.028827   4.774 2.35e-06 ***\nsoil_depth_statsgo   -0.156120   0.039232  -3.979 7.88e-05 ***\nelev_mean             0.034353   0.057964   0.593 0.553668    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5218 on 526 degrees of freedom\nMultiple R-squared:  0.8012,    Adjusted R-squared:  0.7978 \nF-statistic: 235.5 on 9 and 526 DF,  p-value: &lt; 2.2e-16\n\n\n\n# Linear Model\nlm_model2 &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\nlm_wf2 &lt;- workflow() %&gt;%\n  add_recipe(rec2) %&gt;%\n  add_model(lm_model2) %&gt;%\n  fit(data = c_train)\nsummary(extract_fit_engine(lm_wf2))$coefficients\n\n                         Estimate Std. Error     t value     Pr(&gt;|t|)\n(Intercept)          -0.081748780 0.02253641  -3.6274094 3.141820e-04\np_mean                0.532187271 0.03902852  13.6358550 1.809987e-36\naridity              -0.643845847 0.04981868 -12.9237847 2.239196e-33\nsoil_depth_pelletier -0.077194364 0.02911388  -2.6514630 8.256109e-03\nmax_water_content     0.058350264 0.04325039   1.3491270 1.778766e-01\norganic_frac          0.005264932 0.02546817   0.2067260 8.363039e-01\nfrac_snow             0.287464074 0.05163924   5.5667757 4.141554e-08\npet_mean              0.137611570 0.02882695   4.7737118 2.347449e-06\nsoil_depth_statsgo   -0.156119578 0.03923198  -3.9793961 7.878971e-05\nelev_mean             0.034352637 0.05796409   0.5926537 5.536676e-01\n\nlm_data2 &lt;- augment(lm_wf2, new_data = c_test)\nmetrics(lm_data2, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.447\n2 rsq     standard       0.874\n3 mae     standard       0.302\n\n# Random Forest Model\nrf_model2 &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\nrf_wf2 &lt;- workflow() %&gt;%\n  add_recipe(rec2) %&gt;%\n  add_model(rf_model2) %&gt;%\n  fit(data = c_train)\n\nrf_data2 &lt;- augment(rf_wf2, new_data = c_test)\nmetrics(rf_data2, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.290\n2 rsq     standard       0.946\n3 mae     standard       0.191\n\n# Boost Tree\nbt_model2 &lt;- boost_tree() %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n\nbt_wf2 &lt;- workflow() %&gt;%\n  add_recipe(rec2) %&gt;%\n  add_model(bt_model2) %&gt;%\n  fit(data = c_train) \n\nbt_data2 &lt;- augment(bt_wf2, new_data = c_test)\n\nmetrics(bt_data2, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.384\n2 rsq     standard       0.903\n3 mae     standard       0.241\n\n# Neural Network\n\nnnet_model2 &lt;- bag_mlp() %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\")\n\nnnet_wf2 &lt;- workflow() %&gt;%\n  add_recipe(rec2) %&gt;%\n  add_model(nnet_model2) %&gt;%\n  fit(data = c_train) \n\nnnet_data2 &lt;- augment(nnet_wf2, new_data = c_test)\n\nmetrics(nnet_data2, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.303\n2 rsq     standard       0.943\n3 mae     standard       0.203\n\n\n\n# Workflow Set\nwf2 &lt;- workflow_set(list(rec2), list(lm_model2, rf_model2, nnet_model2, bt_model2)) %&gt;%\n  workflow_map('fit_resamples', resamples = c_cv) \n# Evaluation\nautoplot(wf2)\n\n\n\n\n\n\n\nrank_results(wf2, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 8 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_rand_fore… Prepro… rmse    0.389  0.0273    10 recipe       rand…     1\n2 recipe_rand_fore… Prepro… rsq     0.896  0.0107    10 recipe       rand…     1\n3 recipe_bag_mlp    Prepro… rmse    0.399  0.0331    10 recipe       bag_…     2\n4 recipe_bag_mlp    Prepro… rsq     0.888  0.0115    10 recipe       bag_…     2\n5 recipe_boost_tree Prepro… rmse    0.409  0.0312    10 recipe       boos…     3\n6 recipe_boost_tree Prepro… rsq     0.882  0.0106    10 recipe       boos…     3\n7 recipe_linear_reg Prepro… rmse    0.531  0.0335    10 recipe       line…     4\n8 recipe_linear_reg Prepro… rsq     0.800  0.0136    10 recipe       line…     4\n\n\nThe best model evaluating the relationship between logQmean and the predictor variables turned out to be the Neural Network model. Similar to the previous example, the flexibility of this model and its ability to capture complex interactions and relationships makes it the best model. The relationships between variables is non-linear, making the linear model insufficient and decision-tree based models perform better than the linear, but ultimately not as well as the neural network. It ranks first compared to all other model types for its R-squared value, with &gt;94 % of the variation in logQmean being accounted for by the predictor variables. For these reasons the Neural Network model is the best of them all.\n\n# Extract and Evaluate \n# workflow created in initial model creation above\nggplot(nnet_data2, aes(x = logQmean, y = .pred)) +\n  scale_color_viridis_c() +\n  geom_point(color = \"blue\", alpha = 0.6) +\n  geom_abline() +\n  theme_linedraw() +\n  labs(\n    title = \"Observed vs. Predicted Log Mean Streamflow\",\n    x = \"Observed logQmean\",\n    y = \"Predicted logQmean\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe model seems to be a good fit for predicting logQmean across a number of predictor variables. The line of best fit represents the overall trend and slope of the data, although there is some variation between actual and predicted values. I think this model could be fine tuned by including even more predictor variables to increase its predictive capacity. However, no model will be 100% accurate in predicting streamflow on a given day due to daily variations and the presence of outliers, so I think this model is an excellent start for making predictions."
  },
  {
    "objectID": "hyperparameter-tuning.html",
    "href": "hyperparameter-tuning.html",
    "title": "hyperparameter tuning",
    "section": "",
    "text": "# Data Import/Tidy/Transform\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n\n\n✔ broom        1.0.7     ✔ recipes      1.1.1\n✔ dials        1.4.0     ✔ rsample      1.2.1\n✔ dplyr        1.1.4     ✔ tibble       3.2.1\n✔ ggplot2      3.5.1     ✔ tidyr        1.3.1\n✔ infer        1.0.7     ✔ tune         1.3.0\n✔ modeldata    1.4.0     ✔ workflows    1.2.0\n✔ parsnip      1.3.0     ✔ workflowsets 1.1.0\n✔ purrr        1.0.4     ✔ yardstick    1.3.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ lubridate 1.9.4     ✔ stringr   1.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(powerjoin)\nlibrary(glue)\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\n\n# Read in Data\n\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              'data/camels_attributes_v2.0.pdf')\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\n\nlocal_files   &lt;- glue('data/camels_{types}.txt')\n\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \n\ncamels &lt;- power_full_join(camels ,by = 'gauge_id')\n\n\n# Clean Data\n\nlibrary(dplyr)\nlibrary(ggpubr)\nlibrary(skimr)\nlibrary(visdat)\n\ncamels_clean &lt;- camels %&gt;%\n  mutate(across(where(is.character), as.factor)) %&gt;%\n  mutate(logQmean = log(q_mean)) %&gt;%\n  drop_na()\n\nskim(camels_clean)\n\n\nData summary\n\n\nName\ncamels_clean\n\n\nNumber of rows\n507\n\n\nNumber of columns\n59\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n6\n\n\nnumeric\n53\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\ngauge_id\n0\n1\nFALSE\n507\n010: 1, 010: 1, 010: 1, 010: 1\n\n\nhigh_prec_timing\n0\n1\nFALSE\n4\njja: 175, djf: 172, mam: 93, son: 67\n\n\nlow_prec_timing\n0\n1\nFALSE\n4\njja: 189, son: 156, djf: 114, mam: 48\n\n\ngeol_1st_class\n0\n1\nFALSE\n12\nSil: 162, Met: 79, Unc: 79, Car: 69\n\n\ngeol_2nd_class\n0\n1\nFALSE\n13\nSil: 119, Unc: 83, Car: 67, Mix: 62\n\n\ndom_land_cover\n0\n1\nFALSE\n12\n: 99, : 98, : 72, : 64\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\np_mean\n0\n1\n3.15\n1.49\n0.64\n2.20\n3.05\n3.70\n8.94\n▅▇▂▁▁\n\n\npet_mean\n0\n1\n2.80\n0.56\n1.94\n2.37\n2.70\n3.16\n4.74\n▇▇▅▂▁\n\n\np_seasonality\n0\n1\n-0.06\n0.56\n-1.44\n-0.41\n0.08\n0.27\n0.92\n▂▃▃▇▃\n\n\nfrac_snow\n0\n1\n0.19\n0.21\n0.00\n0.04\n0.11\n0.26\n0.91\n▇▂▁▁▁\n\n\naridity\n0\n1\n1.13\n0.67\n0.22\n0.73\n0.89\n1.45\n5.21\n▇▃▁▁▁\n\n\nhigh_prec_freq\n0\n1\n21.00\n4.80\n7.90\n18.45\n22.20\n24.55\n32.70\n▂▃▇▇▁\n\n\nhigh_prec_dur\n0\n1\n1.37\n0.19\n1.10\n1.22\n1.32\n1.47\n2.07\n▇▅▂▁▁\n\n\nlow_prec_freq\n0\n1\n256.92\n36.76\n169.90\n233.57\n259.15\n286.75\n348.70\n▂▅▇▆▁\n\n\nlow_prec_dur\n0\n1\n6.29\n3.46\n2.79\n4.42\n5.14\n7.21\n36.51\n▇▁▁▁▁\n\n\nglim_1st_class_frac\n0\n1\n0.73\n0.19\n0.30\n0.58\n0.76\n0.90\n1.00\n▂▅▅▆▇\n\n\nglim_2nd_class_frac\n0\n1\n0.19\n0.13\n0.00\n0.08\n0.19\n0.30\n0.49\n▇▆▆▅▂\n\n\ncarbonate_rocks_frac\n0\n1\n0.13\n0.26\n0.00\n0.00\n0.00\n0.09\n1.00\n▇▁▁▁▁\n\n\ngeol_porostiy\n0\n1\n0.12\n0.06\n0.01\n0.07\n0.12\n0.17\n0.28\n▆▆▇▆▁\n\n\ngeol_permeability\n0\n1\n-13.86\n1.13\n-16.50\n-14.66\n-13.90\n-13.03\n-10.97\n▂▃▇▅▁\n\n\nsoil_depth_pelletier\n0\n1\n9.45\n15.25\n0.27\n1.00\n1.20\n6.99\n50.00\n▇▁▁▁▁\n\n\nsoil_depth_statsgo\n0\n1\n1.28\n0.27\n0.40\n1.08\n1.42\n1.50\n1.50\n▁▁▂▂▇\n\n\nsoil_porosity\n0\n1\n0.44\n0.02\n0.37\n0.43\n0.44\n0.46\n0.59\n▁▇▂▁▁\n\n\nsoil_conductivity\n0\n1\n1.67\n1.39\n0.45\n0.89\n1.34\n1.89\n10.91\n▇▁▁▁▁\n\n\nmax_water_content\n0\n1\n0.52\n0.15\n0.09\n0.41\n0.53\n0.64\n0.88\n▁▃▆▇▁\n\n\nsand_frac\n0\n1\n35.69\n15.47\n8.18\n24.62\n34.60\n43.77\n91.16\n▅▇▅▁▁\n\n\nsilt_frac\n0\n1\n33.30\n12.82\n4.13\n23.53\n33.65\n42.76\n67.77\n▂▇▇▅▁\n\n\nclay_frac\n0\n1\n20.35\n9.81\n2.08\n13.82\n18.88\n26.58\n50.35\n▃▇▅▂▁\n\n\nwater_frac\n0\n1\n0.02\n0.15\n0.00\n0.00\n0.00\n0.00\n1.71\n▇▁▁▁▁\n\n\norganic_frac\n0\n1\n0.45\n2.97\n0.00\n0.00\n0.00\n0.00\n39.37\n▇▁▁▁▁\n\n\nother_frac\n0\n1\n10.88\n16.94\n0.00\n0.00\n2.25\n15.48\n89.87\n▇▂▁▁▁\n\n\ngauge_lat\n0\n1\n39.55\n5.21\n27.05\n36.23\n39.35\n43.96\n48.66\n▂▃▇▅▆\n\n\ngauge_lon\n0\n1\n-98.08\n16.26\n-124.39\n-112.03\n-97.04\n-83.40\n-67.94\n▇▆▇▇▅\n\n\nelev_mean\n0\n1\n842.40\n824.66\n21.75\n278.50\n492.06\n1055.30\n3457.46\n▇▂▁▁▁\n\n\nslope_mean\n0\n1\n50.12\n48.29\n0.82\n7.97\n36.17\n77.62\n255.69\n▇▃▂▁▁\n\n\narea_gages2\n0\n1\n854.89\n1829.26\n4.03\n151.12\n383.82\n855.14\n25791.04\n▇▁▁▁▁\n\n\narea_geospa_fabric\n0\n1\n870.19\n1837.52\n4.10\n164.23\n397.25\n861.21\n25817.78\n▇▁▁▁▁\n\n\nfrac_forest\n0\n1\n0.61\n0.38\n0.00\n0.20\n0.75\n0.97\n1.00\n▅▁▂▂▇\n\n\nlai_max\n0\n1\n3.00\n1.52\n0.37\n1.63\n2.75\n4.60\n5.58\n▅▇▃▅▇\n\n\nlai_diff\n0\n1\n2.27\n1.32\n0.15\n1.07\n2.06\n3.49\n4.82\n▇▇▆▃▆\n\n\ngvf_max\n0\n1\n0.70\n0.17\n0.18\n0.58\n0.75\n0.86\n0.92\n▁▂▃▃▇\n\n\ngvf_diff\n0\n1\n0.31\n0.15\n0.03\n0.18\n0.29\n0.45\n0.65\n▅▇▅▇▂\n\n\ndom_land_cover_frac\n0\n1\n0.80\n0.19\n0.31\n0.64\n0.84\n0.99\n1.00\n▁▂▃▃▇\n\n\nroot_depth_50\n0\n1\n0.18\n0.03\n0.12\n0.16\n0.18\n0.19\n0.25\n▃▅▇▂▂\n\n\nroot_depth_99\n0\n1\n1.81\n0.30\n1.50\n1.51\n1.79\n2.00\n3.10\n▇▃▂▁▁\n\n\nq_mean\n0\n1\n1.46\n1.61\n0.00\n0.49\n1.00\n1.72\n9.50\n▇▁▁▁▁\n\n\nrunoff_ratio\n0\n1\n0.38\n0.24\n0.00\n0.22\n0.34\n0.51\n1.36\n▇▇▃▁▁\n\n\nslope_fdc\n0\n1\n1.19\n0.53\n0.00\n0.81\n1.24\n1.56\n2.50\n▃▆▇▆▁\n\n\nbaseflow_index\n0\n1\n0.49\n0.17\n0.01\n0.39\n0.51\n0.60\n0.98\n▁▃▇▅▁\n\n\nstream_elas\n0\n1\n1.86\n0.80\n-0.64\n1.33\n1.69\n2.25\n6.24\n▁▇▃▁▁\n\n\nq5\n0\n1\n0.17\n0.25\n0.00\n0.01\n0.08\n0.22\n1.77\n▇▁▁▁▁\n\n\nq95\n0\n1\n4.98\n5.23\n0.00\n1.67\n3.46\n6.29\n31.23\n▇▂▁▁▁\n\n\nhigh_q_freq\n0\n1\n27.15\n30.51\n0.00\n6.92\n16.15\n38.60\n172.80\n▇▂▁▁▁\n\n\nhigh_q_dur\n0\n1\n7.62\n10.98\n0.00\n1.87\n3.24\n8.82\n92.56\n▇▁▁▁▁\n\n\nlow_q_freq\n0\n1\n111.13\n86.38\n0.00\n35.35\n101.35\n173.10\n356.80\n▇▆▅▂▁\n\n\nlow_q_dur\n0\n1\n23.38\n23.12\n0.00\n10.31\n16.92\n28.20\n209.88\n▇▁▁▁▁\n\n\nzero_q_freq\n0\n1\n0.04\n0.13\n0.00\n0.00\n0.00\n0.00\n0.97\n▇▁▁▁▁\n\n\nhfd_mean\n0\n1\n185.49\n34.66\n112.25\n162.07\n177.80\n212.10\n287.75\n▂▇▅▃▁\n\n\nlogQmean\n0\n1\n-0.21\n1.25\n-5.39\n-0.72\n0.00\n0.54\n2.25\n▁▁▂▇▂\n\n\n\n\nvis_miss(camels_clean)\n\n\n\n\n\n\n\nvis_dat(camels_clean)\n\n\n\n\n\n\n\nggplot(camels_clean, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\", color = \"red\", linetype = 2) +\n  scale_color_viridis_c() +\n  theme_linedraw() + \n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n# Data Splitting\n\n\n \n\nset.seed(123)\nsplit &lt;- initial_split(camels_clean, prop = 0.8)\ntrain &lt;- training(split)\ntest  &lt;- testing(split)\n\n\n# Feature Engineering\n\nrec &lt;-  recipe(logQmean ~ aridity + p_mean, data = train) %&gt;%\n  step_log(all_predictors()) %&gt;%\n  step_interact(terms = ~ aridity:p_mean)\n\n\n# Resampling and Model Testing\n\n# 1 build resamples\ncv &lt;- vfold_cv(train, v = 10)\n\n#2 Build 3 candidate models\nbaked_data &lt;- prep(rec, train) |&gt; \n  bake(new_data = NULL)\n\nlm_model &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\nlm_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(lm_model) %&gt;%\n  fit(data = train) \n\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\nrf_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(rf_model) %&gt;%\n  fit(data = train) \n\nbt_model &lt;- boost_tree() %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n\nbt_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(bt_model) %&gt;%\n  fit(data = train) \n\n# 3 Test the Models\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model, bt_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = cv) \n\nautoplot(wf)\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 6 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_linear_reg Prepro… rmse    0.575  0.0337    10 recipe       line…     1\n2 recipe_linear_reg Prepro… rsq     0.780  0.0220    10 recipe       line…     1\n3 recipe_rand_fore… Prepro… rmse    0.577  0.0398    10 recipe       rand…     2\n4 recipe_rand_fore… Prepro… rsq     0.778  0.0240    10 recipe       rand…     2\n5 recipe_boost_tree Prepro… rmse    0.617  0.0409    10 recipe       boos…     3\n6 recipe_boost_tree Prepro… rsq     0.748  0.0276    10 recipe       boos…     3\n\n\n#4 Model Selection I am choosing the random forest model to move forward with. This is because it uses a decision tree based model for regression that will combine predictions from multiple different decision trees that will make the data overall more generalizeable. Despite it performing slightly under the linear model, I thought this would be the best choice as it has hyperparameters that can be tuned to make it perform even better than the linear model once it has been tuned. The engine is ranger and the mode is regression. I think the reason that this model is a good choice for this specific problem is that unlike the linear model, it is capable of capturing nonlinear relationships. Since the log transformations make the relationship between the predicted and predictor variables more linear, I thought it necessary to introduce a model that can capture other relationships that are not being represented by a linear model alone.\n\n# Tuning\n\n#1 Build A Model \nrf_spec &lt;- rand_forest(\n  mtry = tune(),\n  min_n = tune(),\n  trees = 1000) %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\") \n\n#2 Create a Workflow\nrf_spec_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(rf_spec)\n\n#3 Check Tunable Ranges\ndials &lt;- extract_parameter_set_dials(rf_spec)\ndials$object &lt;- finalize(dials$object, train)\n\n#4 Define Search Space\nmy.grid &lt;- grid_latin_hypercube(dials$object, size = 25)\n\nWarning: `grid_latin_hypercube()` was deprecated in dials 1.3.0.\nℹ Please use `grid_space_filling()` instead.\n\n#5 Tune the Model\nmodel_params &lt;-  tune_grid(\n    rf_spec_wf,\n    resamples = cv,\n    grid = my.grid,\n    metrics = metric_set(rmse, rsq, mae),\n    control = control_grid(save_pred = TRUE)\n  )\n\n→ A | warning: ! 53 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\n\n\nThere were issues with some computations   A: x1\n\n\n→ B | warning: ! 46 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\n\n\nThere were issues with some computations   A: x1\n→ C | warning: ! 17 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1\n→ D | warning: ! 18 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1\n→ E | warning: ! 41 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1\n→ F | warning: ! 29 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1\n→ G | warning: ! 35 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1\n→ H | warning: ! 36 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1\n→ I | warning: ! 39 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1\n→ J | warning: ! 44 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1\n→ K | warning: ! 26 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ L | warning: ! 21 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ M | warning: ! 55 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ N | warning: ! 22 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ O | warning: ! 28 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ P | warning: ! 14 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ Q | warning: ! 49 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ R | warning: ! 5 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ S | warning: ! 50 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ T | warning: ! 7 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ U | warning: ! 58 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ V | warning: ! 33 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ W | warning: ! 9 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\n→ X | warning: ! 11 columns were requested but there were 3 predictors in the data.\n                ℹ 3 predictors will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x…\nThere were issues with some computations   A: x2   B: x2   C: x2   D: x2   E: x…\nThere were issues with some computations   A: x3   B: x3   C: x3   D: x2   E: x…\nThere were issues with some computations   A: x3   B: x3   C: x3   D: x3   E: x…\nThere were issues with some computations   A: x4   B: x4   C: x4   D: x4   E: x…\nThere were issues with some computations   A: x5   B: x5   C: x5   D: x5   E: x…\nThere were issues with some computations   A: x6   B: x6   C: x6   D: x6   E: x…\nThere were issues with some computations   A: x7   B: x7   C: x7   D: x7   E: x…\nThere were issues with some computations   A: x8   B: x8   C: x8   D: x7   E: x…\nThere were issues with some computations   A: x8   B: x8   C: x8   D: x8   E: x…\nThere were issues with some computations   A: x9   B: x9   C: x9   D: x9   E: x…\nThere were issues with some computations   A: x10   B: x10   C: x10   D: x10   …\nThere were issues with some computations   A: x10   B: x10   C: x10   D: x10   …\n\nautoplot(model_params)\n\n\n\n\n\n\n\n\nThe randomly selected predictors are representative of the mtry hyperparameter and are largely scattered, indicating that mtry does not have a strong effect on the metrics. The minimal node size is representative of the min_n parameter and suggests that for MAE and RMSE, both values decrease as min_n increases, with the gains tapering off as Minimal Node Size increases past 25. The rsq value increases as min_n increases and levels off, indicating that the model explains more variance with a greater node size, but that these gains lessen after a certain point, about 30. The grid indicates that the most impactful parameter is min_n and the effect of mtry is negligable. The optimal performance of this model would include a min_n with values between 25-35.\n\n#6 Check Skill of Tuned Model\ncollect_metrics(model_params) %&gt;%\n  filter(.metric == \"rsq\") %&gt;%\n  arrange(desc(mean))\n\n# A tibble: 25 × 8\n    mtry min_n .metric .estimator  mean     n std_err .config              \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1    33    39 rsq     standard   0.797    10  0.0245 Preprocessor1_Model23\n 2    41    36 rsq     standard   0.797    10  0.0249 Preprocessor1_Model06\n 3     5    38 rsq     standard   0.797    10  0.0249 Preprocessor1_Model19\n 4    21    34 rsq     standard   0.796    10  0.0248 Preprocessor1_Model13\n 5    14    33 rsq     standard   0.796    10  0.0251 Preprocessor1_Model17\n 6    29    31 rsq     standard   0.795    10  0.0249 Preprocessor1_Model07\n 7     7    29 rsq     standard   0.795    10  0.0248 Preprocessor1_Model21\n 8    28    30 rsq     standard   0.795    10  0.0251 Preprocessor1_Model16\n 9    36    26 rsq     standard   0.794    10  0.0252 Preprocessor1_Model09\n10    35    25 rsq     standard   0.793    10  0.0252 Preprocessor1_Model08\n# ℹ 15 more rows\n\nshow_best(model_params, metric = \"rsq\")\n\n# A tibble: 5 × 8\n   mtry min_n .metric .estimator  mean     n std_err .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1    33    39 rsq     standard   0.797    10  0.0245 Preprocessor1_Model23\n2    41    36 rsq     standard   0.797    10  0.0249 Preprocessor1_Model06\n3     5    38 rsq     standard   0.797    10  0.0249 Preprocessor1_Model19\n4    21    34 rsq     standard   0.796    10  0.0248 Preprocessor1_Model13\n5    14    33 rsq     standard   0.796    10  0.0251 Preprocessor1_Model17\n\nhp_best &lt;- select_best(model_params, metric = \"rsq\")\n\n\n#7 Finalize Model\nfinal_wf &lt;- finalize_workflow(\n  rf_spec_wf,\n  hp_best\n)\n\n\n# Final Model Verification\nfinal_fit &lt;- last_fit(\n  final_wf,\n  split = split\n)\n\n→ A | warning: ! 33 columns were requested but there were 3 predictors in the data.\n               ℹ 3 predictors will be used.\n\ncollect_metrics(final_fit)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       0.623 Preprocessor1_Model1\n2 rsq     standard       0.791 Preprocessor1_Model1\n\n\nThe final model performs slightly worse than on the training data, with this model having an rsq value of 0.789 while the tuned model had a best rsq value of 0.796. I think that because these values are relatively close to each other, the model still is a good representation of the whole dataset and will be able to make pretty accurate predictions.\n\nfinal_preds &lt;- collect_predictions(final_fit)\nprint(final_preds)\n\n# A tibble: 102 × 5\n    .pred id                .row logQmean .config             \n    &lt;dbl&gt; &lt;chr&gt;            &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n 1 0.728  train/test split     1  0.776   Preprocessor1_Model1\n 2 0.633  train/test split    15  0.620   Preprocessor1_Model1\n 3 0.842  train/test split    17  0.805   Preprocessor1_Model1\n 4 0.763  train/test split    19  0.766   Preprocessor1_Model1\n 5 0.683  train/test split    28  0.707   Preprocessor1_Model1\n 6 0.167  train/test split    37  0.0948  Preprocessor1_Model1\n 7 0.247  train/test split    38  0.151   Preprocessor1_Model1\n 8 0.0278 train/test split    44 -0.00956 Preprocessor1_Model1\n 9 0.168  train/test split    46  0.132   Preprocessor1_Model1\n10 0.0129 train/test split    47  0.00388 Preprocessor1_Model1\n# ℹ 92 more rows\n\nlibrary(ggplot2)\n\nggplot(final_preds, aes(x = logQmean, y = .pred)) +\n  geom_point(alpha = 0.6, color = \"#1f78b4\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"#33a02c\") +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"gray30\") +\n  scale_x_continuous(name = \"Actual Values\") +\n  scale_y_continuous(name = \"Predicted Values\") +\n  labs(\n    title = \"Predicted vs Actual Values\",\n    subtitle = \"Final Model Performance on Test Set\"\n  ) +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n# Building a Map\nfinal_model &lt;- fit(final_wf, data = camels_clean)\n\nWarning: ! 33 columns were requested but there were 3 predictors in the data.\nℹ 3 predictors will be used.\n\nlibrary(broom)\naugmented_data &lt;- augment(final_model, new_data = camels_clean) %&gt;%\n  mutate(residual = (.pred - logQmean)^2)\n\nlibrary(ggplot2)\nlibrary(patchwork)\n\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Prediction map\nmap_preds &lt;- ggplot(augmented_data, aes(x = gauge_lon, y = gauge_lat, color = .pred)) +\n  geom_point(alpha = 0.7, size = 1.5) +\n  scale_color_viridis_c(option = \"plasma\", name = \"Prediction\") +\n  ggthemes::theme_map() +\n  coord_fixed() +\n  labs(\n    title = \"Predicted Values\",\n    x = \"Longitude\",\n    y = \"Latitude\"\n  ) +\n  theme_minimal(base_size = 10) +\n  theme(\n    plot.title = element_text(size = 12, face = \"bold\"),\n    axis.title = element_text(size = 10),\n    axis.text = element_text(size = 8),\n    legend.title = element_text(size = 9),\n    legend.text = element_text(size = 8)\n  )\n\n# Residual map\nmap_resid &lt;- ggplot(augmented_data, aes(x = gauge_lon, y = gauge_lat, color = residual)) +\n  geom_point(alpha = 0.7, size = 1.5) +\n  scale_color_viridis_c(option = \"inferno\", trans = \"sqrt\", name = \"Residual\") +\n  ggthemes::theme_map() +\n  coord_fixed() +\n  labs(\n    title = \"Residuals (Squared Error)\",\n    x = \"Longitude\",\n    y = \"Latitude\"\n  ) +\n  theme_minimal(base_size = 10) +\n  theme(\n    plot.title = element_text(size = 12, face = \"bold\"),\n    axis.title = element_text(size = 10),\n    axis.text = element_text(size = 8),\n    legend.title = element_text(size = 9),\n    legend.text = element_text(size = 8)\n  )\n\n# Combine with patchwork\nmap_preds + map_resid + plot_layout(ncol = 2)"
  }
]