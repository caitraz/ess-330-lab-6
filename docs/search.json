[
  {
    "objectID": "lab6.html",
    "href": "lab6.html",
    "title": "Lab 6",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.7     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.0     ✔ yardstick    1.3.2\n✔ recipes      1.1.1     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n\nlibrary(powerjoin)\nlibrary(glue)\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\n\n\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              'data/camels_attributes_v2.0.pdf')\n\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\n\nlocal_files   &lt;- glue('data/camels_{types}.txt')\n\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \n\ncamels &lt;- power_full_join(camels ,by = 'gauge_id')\n\n\nQuestion 1\nThe zero_q_freq variable is the frequency of days where Q = 0 mm/day as a percentage, with Q being discharge, a measure of the volume of water flowing past a point on a stream.\n\n\nExploratory Data Analysis\n\nggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = q_mean)) +\n  scale_color_gradient(low = \"pink\", high = \"dodgerblue\") +\n  ggthemes::theme_map()\n\n\n\n\n\n\n\n\n\n\nQuestion 2\n\ncamels_long &lt;- camels %&gt;%\n  pivot_longer(cols = c(aridity, p_mean), \n               names_to = \"variable\", \n               values_to = \"value\")\n\nggplot(data = camels_long, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = value)) +  \n  scale_color_gradient(low = \"pink\", high = \"dodgerblue\") +\n  ggthemes::theme_map() +\n  facet_wrap(~ variable, scales = \"free\") + \n  scale_color_gradient(low = \"pink\", high = \"dodgerblue\") +\n  labs(\n    title = \"Maps of Aridity and P-Mean\",  \n    x = \"Longitude\", \n    y = \"Latitude\",  \n    color = \"Measurement Value\"  \n  )\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n\n\n\n\n\n\n\n\n\n\nModel Preparation & Building\n\ncamels |&gt; \n  select(aridity, p_mean, q_mean) |&gt; \n  drop_na() |&gt; \n  cor()\n\n           aridity     p_mean     q_mean\naridity  1.0000000 -0.7550090 -0.5817771\np_mean  -0.7550090  1.0000000  0.8865757\nq_mean  -0.5817771  0.8865757  1.0000000\n\n\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\", color = \"red\", linetype = 2) +\n  scale_color_viridis_c() +\n  theme_linedraw() + \n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  scale_color_viridis_c() +\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  scale_color_viridis_c(trans = \"log\") +\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\",\n        legend.key.width = unit(2.5, \"cm\"),\n        legend.key.height = unit(.5, \"cm\")) + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\") \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\n\ncamels &lt;- camels |&gt; \n  mutate(logQmean = log(q_mean))\n\ncamels_split &lt;- initial_split(camels, prop = 0.8)\ncamels_train &lt;- training(camels_split)\ncamels_test  &lt;- testing(camels_split)\n\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n\nrec &lt;-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %&gt;%\n  step_log(all_predictors()) %&gt;%\n  step_interact(terms = ~ aridity:p_mean) |&gt; \n  step_naomit(all_predictors(), all_outcomes())\n\n\nbaked_data &lt;- prep(rec, camels_train) |&gt; \n  bake(new_data = NULL)\n\nlm_base &lt;- lm(logQmean ~ aridity * p_mean, data = baked_data)\nsummary(lm_base)\n\n\nCall:\nlm(formula = logQmean ~ aridity * p_mean, data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity        -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean          1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity:p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\nsummary(lm(logQmean ~ aridity + p_mean + aridity_x_p_mean, data = baked_data))\n\n\nCall:\nlm(formula = logQmean ~ aridity + p_mean + aridity_x_p_mean, \n    data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity          -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean            1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity_x_p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\n\n\ntest_data &lt;-  bake(prep(rec), new_data = camels_test)\ntest_data$lm_pred &lt;- predict(lm_base, newdata = test_data)\n\nmetrics(test_data, truth = logQmean, estimate = lm_pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\nggplot(test_data, aes(x = logQmean, y = lm_pred, colour = aridity)) +\n  scale_color_gradient2(low = \"brown\", mid = \"orange\", high = \"darkgreen\") +\n  geom_point() +\n  geom_abline(linetype = 2) +\n  theme_linedraw() + \n  labs(title = \"Linear Model: Observed vs Predicted\",\n       x = \"Observed Log Mean Flow\",\n       y = \"Predicted Log Mean Flow\",\n       color = \"Aridity\")\n\n\n\n\n\n\n\n\n\nlm_model &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\nlm_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(lm_model) %&gt;%\n  fit(data = camels_train) \n\n\nsummary(extract_fit_engine(lm_wf))$coefficients\n\n                   Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)      -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity          -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean            1.4843771 0.15511117   9.569762 4.022500e-20\naridity_x_p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\nsummary(lm_base)$coefficients\n\n                 Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)    -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity        -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean          1.4843771 0.15511117   9.569762 4.022500e-20\naridity:p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\n\n\nlm_data &lt;- augment(lm_wf, new_data = camels_test)\ndim(lm_data)\n\n[1] 135  61\n\n\n\nmetrics(lm_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\nggplot(lm_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nlibrary(baguette)\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\nrf_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(rf_model) %&gt;%\n  fit(data = camels_train) \n\nrf_data &lt;- augment(rf_wf, new_data = camels_test)\ndim(rf_data)\n\n[1] 135  60\n\nmetrics(rf_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.587\n2 rsq     standard       0.741\n3 mae     standard       0.363\n\nggplot(rf_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv) \n\nautoplot(wf)\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 4 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_rand_fore… Prepro… rmse    0.563  0.0247    10 recipe       rand…     1\n2 recipe_rand_fore… Prepro… rsq     0.771  0.0259    10 recipe       rand…     1\n3 recipe_linear_reg Prepro… rmse    0.569  0.0260    10 recipe       line…     2\n4 recipe_linear_reg Prepro… rsq     0.770  0.0223    10 recipe       line…     2\n\n\n\n\nQuestion 3\n\n# Boost Tree \nbt_model &lt;- boost_tree() %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n\nbt_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(bt_model) %&gt;%\n  fit(data = camels_train) \n\nbt_data &lt;- augment(bt_wf, new_data = camels_test)\ndim(bt_data)\n\n[1] 135  60\n\nmetrics(bt_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.631\n2 rsq     standard       0.702\n3 mae     standard       0.397\n\nggplot(bt_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n# Neural Network\nnnet_model &lt;- bag_mlp() %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\")\n\nnnet_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(nnet_model) %&gt;%\n  fit(data = camels_train) \n\nnnet_data &lt;- augment(nnet_wf, new_data = camels_test)\ndim(nnet_data)\n\n[1] 135  61\n\nmetrics(nnet_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.545\n2 rsq     standard       0.772\n3 mae     standard       0.337\n\nggplot(nnet_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n# Add to existing workflow\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model, nnet_model, bt_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv) \n\nautoplot(wf)\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 8 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_bag_mlp    Prepro… rmse    0.547  0.0282    10 recipe       bag_…     1\n2 recipe_bag_mlp    Prepro… rsq     0.786  0.0234    10 recipe       bag_…     1\n3 recipe_rand_fore… Prepro… rmse    0.564  0.0260    10 recipe       rand…     2\n4 recipe_rand_fore… Prepro… rsq     0.770  0.0266    10 recipe       rand…     2\n5 recipe_linear_reg Prepro… rmse    0.569  0.0260    10 recipe       line…     3\n6 recipe_linear_reg Prepro… rsq     0.770  0.0223    10 recipe       line…     3\n7 recipe_boost_tree Prepro… rmse    0.600  0.0289    10 recipe       boos…     4\n8 recipe_boost_tree Prepro… rsq     0.745  0.0268    10 recipe       boos…     4\n\n\nCompared to the other two models, the Neural Network model outperforms the other models and the Xgboost Regression model underperforms the other models. The linear model is still ranked above the Xgboost model and this could be because the tree-based method of the Xgboost model was not able to capture complexities in the relatively small dataset. However, the linear model was outperformed by the random forest model and neural network, suggesting a simple linear relationship is not sufficient to explain the interactions between terms. The flexible nature of the Neural Network model and its ability to capture complexities of the dataset and learn from complex interactions makes it the best model, as demonstrated in the above table and graph. For these reasons I would continue with the Neural Network model.\n\n\nBuild Your Own\n\n#Data Splitting\nset.seed(124)\n\ncamels &lt;- camels %&gt;%\n  mutate(logQmean = log(q_mean)) %&gt;%\n  select(logQmean, p_mean, aridity, soil_depth_pelletier, max_water_content, organic_frac, frac_snow, pet_mean, soil_depth_statsgo, elev_mean) %&gt;%\n  drop_na()\n\nc_split &lt;- initial_split(camels, prop = 0.8)\nc_train &lt;- training(c_split)\nc_test  &lt;- testing(c_split)\n\nc_cv &lt;- vfold_cv(c_train, v = 10)\n\n\n# Recipe\nrec2 &lt;-  recipe(logQmean ~ . , data = c_train) %&gt;%\n  step_scale(all_predictors()) %&gt;%\n  step_center(all_predictors()) \n\nI chose to use the above formula because it compares the predictors to the log transformed Q mean. Doing a log transformation on the Q mean proved to establish a more predictable relationship between the predictors p_mean and aridity, so I maintained this log transformation. Since there are many predictors, I chose to use step_scale and step_center to normalize the data on a universal scale and allow for more accurate model creation.\n\nc_baked &lt;- prep(rec2, c_train) |&gt; \n  bake(new_data = NULL)\n\nlm_base2 &lt;- lm(logQmean ~ . , data = c_baked)\nsummary(lm_base2)\n\n\nCall:\nlm(formula = logQmean ~ ., data = c_baked)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.7726 -0.1543  0.0502  0.2400  3.9490 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          -0.081749   0.022536  -3.627 0.000314 ***\np_mean                0.532187   0.039029  13.636  &lt; 2e-16 ***\naridity              -0.643846   0.049819 -12.924  &lt; 2e-16 ***\nsoil_depth_pelletier -0.077194   0.029114  -2.651 0.008256 ** \nmax_water_content     0.058350   0.043250   1.349 0.177877    \norganic_frac          0.005265   0.025468   0.207 0.836304    \nfrac_snow             0.287464   0.051639   5.567 4.14e-08 ***\npet_mean              0.137612   0.028827   4.774 2.35e-06 ***\nsoil_depth_statsgo   -0.156120   0.039232  -3.979 7.88e-05 ***\nelev_mean             0.034353   0.057964   0.593 0.553668    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5218 on 526 degrees of freedom\nMultiple R-squared:  0.8012,    Adjusted R-squared:  0.7978 \nF-statistic: 235.5 on 9 and 526 DF,  p-value: &lt; 2.2e-16\n\n\n\n# Linear Model\nlm_model2 &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\nlm_wf2 &lt;- workflow() %&gt;%\n  add_recipe(rec2) %&gt;%\n  add_model(lm_model2) %&gt;%\n  fit(data = c_train)\nsummary(extract_fit_engine(lm_wf2))$coefficients\n\n                         Estimate Std. Error     t value     Pr(&gt;|t|)\n(Intercept)          -0.081748780 0.02253641  -3.6274094 3.141820e-04\np_mean                0.532187271 0.03902852  13.6358550 1.809987e-36\naridity              -0.643845847 0.04981868 -12.9237847 2.239196e-33\nsoil_depth_pelletier -0.077194364 0.02911388  -2.6514630 8.256109e-03\nmax_water_content     0.058350264 0.04325039   1.3491270 1.778766e-01\norganic_frac          0.005264932 0.02546817   0.2067260 8.363039e-01\nfrac_snow             0.287464074 0.05163924   5.5667757 4.141554e-08\npet_mean              0.137611570 0.02882695   4.7737118 2.347449e-06\nsoil_depth_statsgo   -0.156119578 0.03923198  -3.9793961 7.878971e-05\nelev_mean             0.034352637 0.05796409   0.5926537 5.536676e-01\n\nlm_data2 &lt;- augment(lm_wf2, new_data = c_test)\nmetrics(lm_data2, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.447\n2 rsq     standard       0.874\n3 mae     standard       0.302\n\n# Random Forest Model\nrf_model2 &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\nrf_wf2 &lt;- workflow() %&gt;%\n  add_recipe(rec2) %&gt;%\n  add_model(rf_model2) %&gt;%\n  fit(data = c_train)\n\nrf_data2 &lt;- augment(rf_wf2, new_data = c_test)\nmetrics(rf_data2, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.290\n2 rsq     standard       0.946\n3 mae     standard       0.191\n\n# Boost Tree\nbt_model2 &lt;- boost_tree() %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n\nbt_wf2 &lt;- workflow() %&gt;%\n  add_recipe(rec2) %&gt;%\n  add_model(bt_model2) %&gt;%\n  fit(data = c_train) \n\nbt_data2 &lt;- augment(bt_wf2, new_data = c_test)\n\nmetrics(bt_data2, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.384\n2 rsq     standard       0.903\n3 mae     standard       0.241\n\n# Neural Network\n\nnnet_model2 &lt;- bag_mlp() %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\")\n\nnnet_wf2 &lt;- workflow() %&gt;%\n  add_recipe(rec2) %&gt;%\n  add_model(nnet_model2) %&gt;%\n  fit(data = c_train) \n\nnnet_data2 &lt;- augment(nnet_wf2, new_data = c_test)\n\nmetrics(nnet_data2, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.303\n2 rsq     standard       0.943\n3 mae     standard       0.203\n\n\n\n# Workflow Set\nwf2 &lt;- workflow_set(list(rec2), list(lm_model2, rf_model2, nnet_model2, bt_model2)) %&gt;%\n  workflow_map('fit_resamples', resamples = c_cv) \n# Evaluation\nautoplot(wf2)\n\n\n\n\n\n\n\nrank_results(wf2, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 8 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_rand_fore… Prepro… rmse    0.389  0.0273    10 recipe       rand…     1\n2 recipe_rand_fore… Prepro… rsq     0.896  0.0107    10 recipe       rand…     1\n3 recipe_bag_mlp    Prepro… rmse    0.399  0.0331    10 recipe       bag_…     2\n4 recipe_bag_mlp    Prepro… rsq     0.888  0.0115    10 recipe       bag_…     2\n5 recipe_boost_tree Prepro… rmse    0.409  0.0312    10 recipe       boos…     3\n6 recipe_boost_tree Prepro… rsq     0.882  0.0106    10 recipe       boos…     3\n7 recipe_linear_reg Prepro… rmse    0.531  0.0335    10 recipe       line…     4\n8 recipe_linear_reg Prepro… rsq     0.800  0.0136    10 recipe       line…     4\n\n\nThe best model evaluating the relationship between logQmean and the predictor variables turned out to be the Neural Network model. Similar to the previous example, the flexibility of this model and its ability to capture complex interactions and relationships makes it the best model. The relationships between variables is non-linear, making the linear model insufficient and decision-tree based models perform better than the linear, but ultimately not as well as the neural network. It ranks first compared to all other model types for its R-squared value, with &gt;94 % of the variation in logQmean being accounted for by the predictor variables. For these reasons the Neural Network model is the best of them all.\n\n# Extract and Evaluate \n# workflow created in initial model creation above\nggplot(nnet_data2, aes(x = logQmean, y = .pred)) +\n  scale_color_viridis_c() +\n  geom_point(color = \"blue\", alpha = 0.6) +\n  geom_abline() +\n  theme_linedraw() +\n  labs(\n    title = \"Observed vs. Predicted Log Mean Streamflow\",\n    x = \"Observed logQmean\",\n    y = \"Predicted logQmean\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe model seems to be a good fit for predicting logQmean across a number of predictor variables. The line of best fit represents the overall trend and slope of the data, although there is some variation between actual and predicted values. I think this model could be fine tuned by including even more predictor variables to increase its predictive capacity. However, no model will be 100% accurate in predicting streamflow on a given day due to daily variations and the presence of outliers, so I think this model is an excellent start for making predictions."
  }
]